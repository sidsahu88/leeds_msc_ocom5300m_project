{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Y7H7qzm5lmY7HQz_gIo1RLt3AeQQxSsq","timestamp":1701890266468}],"gpuType":"T4","authorship_tag":"ABX9TyO5qHySexbCcmZqQxuC+Zem"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Environment Setup"],"metadata":{"id":"HCBOs6kKz5ke"}},{"cell_type":"markdown","source":["Installing Huggingface datasets to access Tiny-ImageNet dataset (One-time activity)"],"metadata":{"id":"ankpNpBE8vr1"}},{"cell_type":"code","source":["pip install datasets[vision]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0P4jiKA9ErR","executionInfo":{"status":"ok","timestamp":1701889679790,"user_tz":300,"elapsed":7224,"user":{"displayName":"Siddharth Sahu","userId":"13238428815416750697"}},"outputId":"61d48024-f4bc-4d36-b5c8-60da35aeaf04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets[vision] in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (9.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (6.0.1)\n","Requirement already satisfied: Pillow>=6.2.1 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]) (9.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]) (4.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets[vision]) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets[vision]) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[vision]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[vision]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[vision]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets[vision]) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[vision]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[vision]) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets[vision]) (1.16.0)\n"]}]},{"cell_type":"markdown","source":["Importing required libraries"],"metadata":{"id":"O8M_r6hdzyct"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.optim import Adam\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, transforms\n","\n","from datasets import load_dataset\n","\n","from scipy.stats import pearsonr, spearmanr, kendalltau"],"metadata":{"id":"U1GSRV09zxjw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KyAPzJ3eiyPV"},"source":["Device (CPU/GPU) available to use."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1701889679791,"user":{"displayName":"Siddharth Sahu","userId":"13238428815416750697"},"user_tz":300},"id":"KV2qBbsRiyPW","outputId":"597d9139-99f8-4be4-d544-4d1d992f90f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"]},{"cell_type":"markdown","source":["## DataLoaders"],"metadata":{"id":"xWgd5GNc3VtI"}},{"cell_type":"code","source":["class TinyImageNetDataset(Dataset):\n","    def __init__(self, split='train'):\n","        '''\n","        split: Valid values are ['train', 'valid']\n","        '''\n","        self.transform = transforms.Compose([\n","                            transforms.ToTensor(),\n","                            transforms.Resize(64),      # Size of a tiny-imagenet image: (64, 64)\n","                            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n","\n","        self.dataset = load_dataset('Maysee/tiny-imagenet', split=split)\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, index):\n","        image = self.dataset[index]['image']\n","        image = image.convert(\"RGB\")\n","        transformed_img = self.transform(image)\n","        return transformed_img, self.dataset[index]['label']"],"metadata":{"id":"yMfNPC2C8Zz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def image_dataloader(dataset='mnist', batch_size=100):\n","    if dataset == 'mnist':\n","        transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize((0.1307,), (0.3081,))])\n","\n","        trainset = datasets.MNIST('/data/mnist', train=True, download=True, transform=transform)\n","        testset = datasets.MNIST('/data/mnist', train=False, download=True, transform=transform)\n","\n","    elif dataset == 'cifar10':\n","        transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Resize(32),      # Size of a cifar10 image: (32, 32)\n","                transforms.Normalize((0.485, 0.456, 0.406) , (0.229, 0.224, 0.225))])\n","\n","        trainset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n","        testset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n","\n","    elif dataset == 'tinyimagenet':\n","        trainset = TinyImageNetDataset(split='train')\n","        testset = TinyImageNetDataset(split='valid')\n","\n","    else:\n","        raise ValueError(\"Argument 'dataset' must be one of the values in ['cifar10, 'tinyimagenet'].\")\n","\n","    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, test_loader"],"metadata":{"id":"qPHBXuD5cNOk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Capsule Network"],"metadata":{"id":"JfwI1y6qqIm9"}},{"cell_type":"markdown","source":["### Convolutional Layer"],"metadata":{"id":"nxHQWdt34YZU"}},{"cell_type":"code","source":["class ConvLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels=256, kernel_size=9, stride=1, *args, **kwargs):\n","        super(ConvLayer, self).__init__(*args, **kwargs)\n","\n","        self.conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n","\n","    def forward(self, x):\n","        return F.relu(self.conv_layer(x))"],"metadata":{"id":"ONqK8qgnmIyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_conv_out_dim(img_h, img_w, kernel_size, stride, padding=0):\n","    out_h = (int((img_h + (2*padding) - kernel_size) / stride)) + 1\n","    out_w = (int((img_w + (2*padding) - kernel_size) / stride)) + 1\n","    return out_h, out_w"],"metadata":{"id":"xN-8NclADMiv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Primary Capsule Layer"],"metadata":{"id":"4dm8_CTk4gOA"}},{"cell_type":"code","source":["def squash(tensor, dim=-1):\n","    sqr_norm = torch.sum(tensor**2, dim=dim, keepdim=True)\n","    norm = torch.sqrt(sqr_norm)\n","    return (sqr_norm * tensor) / ((1. + sqr_norm) * norm)"],"metadata":{"id":"hWQ-hFyZHzZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PrimaryCapsLayer(nn.Module):\n","    def __init__(self, in_channels=256, out_channels=32, out_caps_dim=8, kernel_size=9, stride=2, padding='valid', *args, **kwargs):\n","        super(PrimaryCapsLayer, self).__init__(*args, **kwargs)\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.out_caps_dim = out_caps_dim\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.n_prim_caps = None\n","\n","        self.primary_caps = nn.ModuleList(\n","            [nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n","             for _ in range(out_caps_dim)])\n","\n","    def forward(self, x):\n","        if self.n_prim_caps is None:\n","            conv_out_dim1, conv_out_dim2 = get_conv_out_dim(x.size(-2),             # Calculate convolutional output dimension for zero padding\n","                                                            x.size(-1),\n","                                                            self.kernel_size,\n","                                                            self.stride)\n","            self.n_prim_caps = conv_out_dim1 * conv_out_dim2 * self.out_channels    # Get number of capsules in the output\n","\n","        batch_size = x.size(0)\n","        u_list = [capsule(x) for capsule in self.primary_caps]  # Output capsule shape: (batch_size, out_channels, conv_out_dim1, conv_out_dim2)\n","        u = torch.stack(u_list, dim=-1)                         # Stacking capsule output to get shape: (batch_size, out_channels, conv_out_dim1, conv_out_dim2, out_caps_dim)\n","        u = u.view(batch_size, self.n_prim_caps, -1)            # Reshape the tensor to (batch_size, prim_caps_out_dim, out_caps_dim)\n","        return squash(u)                                        # Squash returns the tensor shape: (batch_size, prim_caps_out_dim, out_caps_dim)"],"metadata":{"id":"75IPzWD4uQ2H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Class Capsule Layer"],"metadata":{"id":"hOOjsdv14lgx"}},{"cell_type":"code","source":["class ClassCapsLayer(nn.Module):\n","    def __init__(self, n_class, n_prim_caps, in_caps_dim=8, out_caps_dim=16, *args, **kwargs):\n","        super(ClassCapsLayer, self).__init__(*args, **kwargs)\n","\n","        self.n_class = n_class\n","        self.n_prim_caps = n_prim_caps\n","        self.in_caps_dim = in_caps_dim\n","        self.out_caps_dim = out_caps_dim\n","\n","        self.weights = nn.Parameter(torch.randn(n_prim_caps, n_class, out_caps_dim, in_caps_dim))\n","\n","    def forward(self, u):\n","        batch_size = u.size(0)\n","        W = torch.stack([self.weights] * batch_size, dim=0)           # W Shape: (batch_size, n_prim_caps, n_class, out_caps_dim, in_caps_dim)\n","        print(\"W shape: \", W.size())\n","        u = torch.stack([u] * self.n_class, dim=2).unsqueeze(-1)    # u Shape: (batch_size, n_prim_caps, n_class, in_caps_dim, 1)\n","        print(\"u shape: \", u.size())\n","        u_hat = torch.matmul(W, u)      # u_hat Shape: (batch_size, n_prim_caps, n_class, out_caps_dim, 1)\n","        return u_hat"],"metadata":{"id":"GdjPQvwRkMWQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Routing Aggreement"],"metadata":{"id":"bI2rqqQY4o9X"}},{"cell_type":"code","source":["class RoutingByAggreement(nn.Module):\n","    def __init__(self, n_in_caps, n_out_caps,  n_iterations=3, *args, **kwargs):\n","        super(RoutingByAggreement, self).__init__(*args, **kwargs)\n","\n","        self.n_in_caps = n_in_caps\n","        self.n_out_caps = n_out_caps\n","        self.n_iterations = n_iterations\n","\n","    def forward(self, u_hat):\n","        print(\"u_hat: \", u_hat.size())\n","        batch_size = u_hat.size(0)      # u_hat Shape: (batch_size, n_in_caps, n_out_caps, output_capsule_dim, 1)\n","\n","        bij = Variable(torch.zeros(batch_size, self.n_in_caps, self.n_out_caps, 1, 1, dtype=torch.float, device=device)) # bij Shape: (batch_size, n_in_caps, n_out_caps, 1, 1)\n","        print(\"bij shape: \", bij.shape)\n","\n","        for r in range(self.n_iterations):\n","            cij = F.softmax(bij, dim=2)                             # cij Shape: (batch_size, n_in_caps, n_out_caps, 1, 1)\n","            print(\"cij shape: \", cij.shape)\n","            sj = torch.mul(cij, u_hat).sum(dim=1, keepdim=True)     # sj Shape: (batch_size, 1, n_out_caps, output_capsule_dim, 1)\n","            print(\"sj shape: \", sj.shape)\n","            vj = squash(sj, dim=-2)                                 # vj Shape: (batch_size, 1, n_out_caps, output_capsule_dim, 1)\n","            vj_in_caps = torch.cat([vj] * self.n_in_caps, dim=1)          # vj Shape: (batch_size, n_in_caps, n_out_caps, output_capsule_dim, 1)\n","            u_hat_T = u_hat.transpose(-2, -1)\n","            print(\"vj_in_caps shape: \", vj_in_caps.shape)\n","            print(\"u_hat_T shape: \", u_hat_T.shape)\n","\n","            if r < self.n_iterations - 1:\n","                #aij = (u_hat * vj).sum(dim=-2, keepdim=True)        # aij Shape: (batch_size, n_in_caps, n_out_caps, 1, 1)\n","                aij = torch.matmul(u_hat_T, vj_in_caps)\n","                print(\"aij shape: \", aij.shape)\n","                bij = bij + aij\n","\n","        print(\"vj squeezed shape: \", vj.squeeze(1).shape)\n","        return vj.squeeze(1)     # vj Shape Squeezed: (batch_size, n_out_caps, output_capsule_dim, 1) [100, 2048, 10, 16, 1]"],"metadata":{"id":"kAj4tpDIzfpy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder Network"],"metadata":{"id":"YWkUFAg14uWn"}},{"cell_type":"code","source":["class CapsDecoder(nn.Module):\n","    def __init__(self, n_class, in_img_c, in_img_h, in_img_w, out_capsule_dim=16, *args, **kwargs):\n","        super(CapsDecoder, self).__init__(*args, **kwargs)\n","\n","        self.n_class = n_class\n","        self.in_img_c = in_img_c\n","        self.in_img_h = in_img_h\n","        self.in_img_w = in_img_w\n","\n","        fcl_input_dim = out_capsule_dim * n_class\n","        fcl_ouput_dim = in_img_c * in_img_h * in_img_w\n","\n","        self.fully_conn_layers = nn.Sequential(\n","            nn.Linear(fcl_input_dim, 512),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(512, 1024),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(1024, fcl_ouput_dim),\n","            nn.Sigmoid())\n","\n","    def forward(self, v):\n","        print(\"v shape: \", v.shape)\n","        caps_out_class = torch.sqrt((v ** 2).sum(dim=-2))   # v shape: (batch_size, n_class, out_capsule_dim, 1)\n","        print(\"caps_out_class shape:\", caps_out_class.shape)\n","        print(\"caps_out_class: \", caps_out_class[0])\n","        caps_out_class = F.softmax(caps_out_class, dim=0)      # caps_out_class Shape: (batch_size, n_class)\n","        print(\"caps_out_class shape after softmax: \", caps_out_class.shape)\n","        print(\"caps_out_class: \", caps_out_class[0])\n","        max_class_indices = caps_out_class.argmax(dim=-1)\n","        print(\"max_class_indices: \",max_class_indices[0])\n","        masked_matrix = Variable(torch.eye(self.n_class, device=device))\n","        masked_matrix = masked_matrix.index_select(dim=0, index=max_class_indices.squeeze())       # masked_matrix Shape: (batch_size, n_class)\n","        print(\"Mask matrix shape: \", masked_matrix)\n","\n","        v = v * masked_matrix[:, :, None, None]           # v Shape: (batch_size, n_class, out_capsule_dim, 1)\n","        flattened_v = v.view(v.size(0), -1)         # flattened_v Shape: (batch_size, n_class * out_capsule_dim * 1)\n","\n","        reconstructed_img = self.fully_conn_layers(flattened_v)    # reconstructed_img Shape: (batch_size, fcl_ouput_dim)\n","        reconstructed_img = reconstructed_img.view(-1, self.in_img_c, self.in_img_h, self.in_img_w)   # reconstructed_img Shape: (batch_size, in_img_ch, in_img_h, in_img_w)\n","\n","        return reconstructed_img"],"metadata":{"id":"FNjqBK-6EQxB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Capsule Network Loss"],"metadata":{"id":"hO866snw4zXX"}},{"cell_type":"code","source":["class CapsNetLoss(nn.Module):\n","    def __init__(self, lmbda=0.5, m_positive=0.9, m_negative=0.1, recon_loss_scale_factor=0.0005, *args, **kwargs):\n","        super(CapsNetLoss, self).__init__(*args, **kwargs)\n","\n","        self.lmbda = lmbda\n","        self.m_positive = m_positive\n","        self.m_negative = m_negative\n","        self.recon_loss_scale_factor = recon_loss_scale_factor\n","        self.mse_loss = nn.MSELoss()\n","\n","    def forward(self, v, labels, images, reconstructed_images):\n","        return self.margin_loss(v, labels) + self.reconstruction_loss(images, reconstructed_images)\n","\n","    def margin_loss(self, v, labels):\n","        vk = torch.sqrt((v**2).sum(dim=-1, keepdim=True))\n","\n","        batch_size = v.size(0)\n","\n","        present_error = F.relu(self.m_positive - vk).view(batch_size, -1)**2\n","        absent_error = F.relu(vk - self.m_negative).view(batch_size, -1)**2\n","\n","        Tk = F.one_hot(labels)\n","\n","        loss = (Tk * present_error) + (self.lmbda * (1 - Tk) * absent_error)\n","        loss = loss.sum(dim=1).mean()\n","\n","        return loss\n","\n","    def reconstruction_loss(self, images, reconstructed_images):\n","        return self.mse_loss(reconstructed_images, images) * self.recon_loss_scale_factor\n"],"metadata":{"id":"tpfoLi4aLKwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BaseCapsuleNetwork(nn.Module):\n","    def __init__(self, in_img_c, in_img_h, in_img_w, n_class, *args, **kwargs):\n","        super(BaseCapsuleNetwork, self).__init__(*args, **kwargs)\n","\n","        self.conv_layer = ConvLayer(in_channels=in_img_c, kernel_size=9, stride=1)\n","\n","        conv_layer_out_dim1, conv_layer_out_dim2 = get_conv_out_dim(in_img_h, in_img_w, kernel_size=9, stride = 1)\n","\n","        self.primary_caps = PrimaryCapsLayer(out_channels=32, kernel_size=9, stride=2)\n","\n","        prim_caps_out_dim1, prim_caps_out_dim2 = get_conv_out_dim(conv_layer_out_dim1, conv_layer_out_dim2, kernel_size=9, stride = 2)\n","        n_prim_caps = prim_caps_out_dim1 * prim_caps_out_dim2 * 32\n","\n","        self.class_caps = ClassCapsLayer(n_class=n_class, n_prim_caps=n_prim_caps)\n","        self.routing_aggreement = RoutingByAggreement(n_in_caps=n_prim_caps, n_out_caps=n_class)\n","        self.caps_decoder = CapsDecoder(n_class, in_img_c, in_img_h, in_img_w)\n","\n","    def forward(self, images):\n","        conv_output = self.conv_layer(images)\n","        primary_caps_output = self.primary_caps(conv_output)\n","        class_caps_output = self.class_caps(primary_caps_output)\n","        pred = self.routing_aggreement(class_caps_output)\n","        reconstructed_img = self.caps_decoder(pred)\n","        return reconstructed_img, pred\n"],"metadata":{"id":"_pCjc5qTckX1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# base_capsnet_cifar10 = BaseCapsuleNetwork(3, 32, 32, n_class=10)\n","# base_capsnet_cifar10 = base_capsnet_cifar10.to(device)\n","# optimizer = Adam(base_capsnet_cifar10.parameters())\n","\n","# train_loader, test_loader = image_dataloader(dataset='cifar10')"],"metadata":{"id":"HAzi15-uLJjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_capsnet_mnist = BaseCapsuleNetwork(1, 28, 28, n_class=10)\n","base_capsnet_mnist = base_capsnet_mnist.to(device)\n","optimizer = Adam(base_capsnet_mnist.parameters())\n","\n","train_loader, test_loader = image_dataloader(dataset='mnist')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poSO8KNIEAyJ","executionInfo":{"status":"ok","timestamp":1701889682652,"user_tz":300,"elapsed":2866,"user":{"displayName":"Siddharth Sahu","userId":"13238428815416750697"}},"outputId":"b2622dbd-d75a-470b-bfac-bac64afca773"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 80996115.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 19191332.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 25778920.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 15488234.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n","\n"]}]},{"cell_type":"code","source":["criterion = CapsNetLoss()\n","n_epochs = 10"],"metadata":{"id":"fFAP1h-96nGq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = []\n","\n","for epoch in range(1, n_epochs+1):\n","    #base_capsnet_cifar10.train()\n","    base_capsnet_mnist.train()\n","    train_loss = 0.0\n","\n","    for batch_idx, (images, labels) in enumerate(train_loader):\n","        batch_size = len(images)\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        #reconstructed_images, preds = base_capsnet_cifar10(images)\n","        reconstructed_images, preds = base_capsnet_mnist(images)\n","\n","        print(\"Reconstructed Image: \", reconstructed_images[0].shape)\n","\n","        loss = criterion(preds, labels, images, reconstructed_images)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss\n","\n","        losses.append(loss)\n","\n","        if batch_idx != 0 and batch_idx % 100 == 0:\n","                # avg_train_loss = train_loss/100\n","                #losses.append(avg_train_loss)\n","                print('Epoch: {} \\tTraining Loss: {:.8f}'.format(epoch, loss))\n","                train_loss = 0 # reset accumulated training loss\n","\n","    print(\"Average Train Loss: \", train_loss / len(train_loader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tSVXDJuaOfQB","executionInfo":{"status":"error","timestamp":1701889995104,"user_tz":300,"elapsed":4374,"user":{"displayName":"Siddharth Sahu","userId":"13238428815416750697"}},"outputId":"3679f020-55e8-451c-8758-db7cf515e298"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["W shape:  torch.Size([100, 1152, 10, 16, 8])\n","u shape:  torch.Size([100, 1152, 10, 8, 1])\n","u_hat:  torch.Size([100, 1152, 10, 16, 1])\n","bij shape:  torch.Size([100, 1152, 10, 1, 1])\n","cij shape:  torch.Size([100, 1152, 10, 1, 1])\n","sj shape:  torch.Size([100, 1, 10, 16, 1])\n","vj_in_caps shape:  torch.Size([100, 1152, 10, 16, 1])\n","u_hat_T shape:  torch.Size([100, 1152, 10, 1, 16])\n","aij shape:  torch.Size([100, 1152, 10, 1, 1])\n","cij shape:  torch.Size([100, 1152, 10, 1, 1])\n","sj shape:  torch.Size([100, 1, 10, 16, 1])\n","vj_in_caps shape:  torch.Size([100, 1152, 10, 16, 1])\n","u_hat_T shape:  torch.Size([100, 1152, 10, 1, 16])\n","aij shape:  torch.Size([100, 1152, 10, 1, 1])\n","cij shape:  torch.Size([100, 1152, 10, 1, 1])\n","sj shape:  torch.Size([100, 1, 10, 16, 1])\n","vj_in_caps shape:  torch.Size([100, 1152, 10, 16, 1])\n","u_hat_T shape:  torch.Size([100, 1152, 10, 1, 16])\n","vj squeezed shape:  torch.Size([100, 10, 16, 1])\n","v shape:  torch.Size([100, 10, 16, 1])\n","caps_out_class shape: torch.Size([100, 10, 1])\n","caps_out_class:  tensor([[0.9998],\n","        [0.9998],\n","        [0.9998],\n","        [0.9998],\n","        [0.9998],\n","        [0.9998],\n","        [0.9998],\n","        [0.9998],\n","        [0.9998],\n","        [0.9998]], grad_fn=<SelectBackward0>)\n","caps_out_class shape after softmax:  torch.Size([100, 10, 1])\n","caps_out_class:  tensor([[0.0100],\n","        [0.0100],\n","        [0.0100],\n","        [0.0100],\n","        [0.0100],\n","        [0.0100],\n","        [0.0100],\n","        [0.0100],\n","        [0.0100],\n","        [0.0100]], grad_fn=<SelectBackward0>)\n","max_class_indices:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-23-d9e0fbe56b8d>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  caps_out_class = F.softmax(caps_out_class) #, dim=-1)      # caps_out_class Shape: (batch_size, n_class)\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-6ad8f24b0197>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#reconstructed_images, preds = base_capsnet_cifar10(images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mreconstructed_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_capsnet_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reconstructed Image: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-84b99e08e8d8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclass_caps_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary_caps_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouting_aggreement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_caps_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mreconstructed_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaps_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreconstructed_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-d9e0fbe56b8d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_class_indices: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_class_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmasked_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mmasked_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_class_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# masked_matrix Shape: (batch_size, n_class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mask matrix shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index_select(): Index is supposed to be a vector"]}]},{"cell_type":"code","source":["base_capsnet_cifar10.eval()\n","test_loss = 0\n","\n","for batch_id, (data, target) in enumerate(test_loader):\n","    batch_size = len(images)\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    reconstructed_images, preds, masked_preds = base_capsnet_cifar10(images)\n","    loss = criterion(preds, labels, images, reconstructed_images)\n","\n","    test_loss += loss\n","\n","    if batch_id % 100 == 0:\n","        print(\"Test Accuracy:\", sum(np.argmax(masked_preds.data.cpu().numpy(), 1) ==\n","                                np.argmax(labels.data.cpu().numpy())) / float(batch_size))\n","\n","print(\"Test Loss: \", test_loss / len(test_loader))"],"metadata":{"id":"_L7c0P6OaiJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","def plot_images_separately(images):\n","    fig = plt.figure()\n","    for j in range(1, 7):\n","        ax = fig.add_subplot(1, 6, j)\n","        image = images[j-1]\n","        ax.imshow(image.T)\n","        plt.xticks(np.array([]))\n","        plt.yticks(np.array([]))\n","    plt.show()"],"metadata":{"id":"C-b5HngHfDLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_images_separately(images[:6, :].cpu())"],"metadata":{"id":"qtqTaY8LfGp4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images[0]"],"metadata":{"id":"QgzeJo03fVdu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels[0]"],"metadata":{"id":"JfSt4F6AkpiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(images[1].cpu().T)"],"metadata":{"id":"rdahY8nvhL8n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["recon_image = reconstructed_images[5]\n","recon_image = recon_image.cpu().detach().numpy()\n","\n","plt.imshow(recon_image.T)"],"metadata":{"id":"_SqwYQjuibrg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torchvision\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# functions to show an image\n","\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","# get some random training images\n","dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' '.join(f'{classes[labels[j]]:5s}' for j in range(100)))"],"metadata":{"id":"IUamYcUhikMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z5Y6sSMWjngD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Sangita Try\n"],"metadata":{"id":"OWEj1bnFjYWO"}},{"cell_type":"code","source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.optim import Adam\n","from torchvision import datasets, transforms\n","\n","USE_CUDA = True"],"metadata":{"id":"W7e7_aUSjbZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Mnist:\n","    def __init__(self, batch_size):\n","        dataset_transform = transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ])\n","\n","        train_dataset = datasets.MNIST('../data', train=True, download=True, transform=dataset_transform)\n","        test_dataset = datasets.MNIST('../data', train=False, download=True, transform=dataset_transform)\n","\n","        self.train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"],"metadata":{"id":"CMvx-xkAjgMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ConvLayer(nn.Module):\n","    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n","        super(ConvLayer, self).__init__()\n","\n","        self.conv = nn.Conv2d(in_channels=in_channels,\n","                               out_channels=out_channels,\n","                               kernel_size=kernel_size,\n","                               stride=1\n","                             )\n","\n","    def forward(self, x):\n","        return F.relu(self.conv(x))"],"metadata":{"id":"mIx42NN3jix3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PrimaryCaps(nn.Module):\n","    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9):\n","        super(PrimaryCaps, self).__init__()\n","\n","        self.capsules = nn.ModuleList([\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0)\n","                          for _ in range(num_capsules)])\n","\n","    def forward(self, x):\n","        u = [capsule(x) for capsule in self.capsules]\n","        u = torch.stack(u, dim=1)\n","        u = u.view(x.size(0), 32 * 6 * 6, -1)\n","        return self.squash(u)\n","\n","    def squash(self, input_tensor):\n","        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n","        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n","        return output_tensor"],"metadata":{"id":"pwfNwZlFjmzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DigitCaps(nn.Module):\n","    def __init__(self, num_capsules=10, num_routes=32 * 6 * 6, in_channels=8, out_channels=16):\n","        super(DigitCaps, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.num_routes = num_routes\n","        self.num_capsules = num_capsules\n","\n","        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n","\n","        W = torch.cat([self.W] * batch_size, dim=0)\n","        u_hat = torch.matmul(W, x)\n","\n","        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n","        if USE_CUDA:\n","            b_ij = b_ij.cuda()\n","\n","        num_iterations = 3\n","        for iteration in range(num_iterations):\n","            c_ij = F.softmax(b_ij)\n","            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n","\n","            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n","            v_j = self.squash(s_j)\n","\n","            if iteration < num_iterations - 1:\n","                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n","                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n","\n","        return v_j.squeeze(1)\n","\n","    def squash(self, input_tensor):\n","        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n","        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n","        return output_tensor"],"metadata":{"id":"k4am3BzTjq9e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","\n","        self.reconstraction_layers = nn.Sequential(\n","            nn.Linear(16 * 10, 512),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(512, 1024),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(1024, 784),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x, data):\n","        classes = torch.sqrt((x ** 2).sum(2))\n","        classes = F.softmax(classes)\n","\n","        _, max_length_indices = classes.max(dim=1)\n","        masked = Variable(torch.sparse.torch.eye(10))\n","        if USE_CUDA:\n","            masked = masked.cuda()\n","        masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n","\n","        reconstructions = self.reconstraction_layers((x * masked[:, :, None, None]).view(x.size(0), -1))\n","        reconstructions = reconstructions.view(-1, 1, 28, 28)\n","\n","        return reconstructions, masked"],"metadata":{"id":"eS8CkBL8jwCt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CapsNet(nn.Module):\n","    def __init__(self):\n","        super(CapsNet, self).__init__()\n","        self.conv_layer = ConvLayer()\n","        self.primary_capsules = PrimaryCaps()\n","        self.digit_capsules = DigitCaps()\n","        self.decoder = Decoder()\n","\n","        self.mse_loss = nn.MSELoss()\n","\n","    def forward(self, data):\n","        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n","        reconstructions, masked = self.decoder(output, data)\n","        return output, reconstructions, masked\n","\n","    def loss(self, data, x, target, reconstructions):\n","        return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n","\n","    def margin_loss(self, x, labels, size_average=True):\n","        batch_size = x.size(0)\n","\n","        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n","\n","        left = F.relu(0.9 - v_c).view(batch_size, -1)\n","        right = F.relu(v_c - 0.1).view(batch_size, -1)\n","\n","        loss = labels * left + 0.5 * (1.0 - labels) * right\n","        loss = loss.sum(dim=1).mean()\n","\n","        return loss\n","\n","    def reconstruction_loss(self, data, reconstructions):\n","        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n","        return loss * 0.0005"],"metadata":{"id":"ata1eu8jj0YT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["capsule_net = CapsNet()\n","if USE_CUDA:\n","    capsule_net = capsule_net.cuda()\n","optimizer = Adam(capsule_net.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"avd4_cfxj2CE","executionInfo":{"status":"error","timestamp":1701890198870,"user_tz":300,"elapsed":679,"user":{"displayName":"Siddharth Sahu","userId":"13238428815416750697"}},"outputId":"58dfd6da-28be-45d5-8cbe-85988c8bb4bb"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-48a6d449d17b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcapsule_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCapsNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcapsule_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsule_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}]}]}